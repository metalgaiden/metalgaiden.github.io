---
layout: page
title: "Epistagraph"
permalink: /projects/epistagraph/
---
Epistagraph is a design tool for non-linear puzzle design.
It allows you to plan out interconnected puzzles and have an idea of what the player might be expected to know beforehand or what they will learn as they play. It can be found in a pre-alpha state on github [here](https://github.com/metalgaiden/epistagraph).

Secrets, Codes, Puzzles. What do these things have in common? The way that they are solved. They all require knowledge to solve, and in fact, once you have knowledge of the solution, there isn’t much solving left to do. In recent years we have seen the rise of game guides and youtube explanations of secrets and unlocks, Giving us all the answers we could ever want, and yet, many people still find the puzzles compelling, finding it frustrating when designers let the community become a mandatory resource to discover all it has to offer. I hope to remedy that. This tool is designed to give the designer confidence that the secrets or puzzles they make are in fact solvable, and with just the tools the game provides.

For all other progression systems and economies we can map out what resources go where, when the player should hit what level, and how long it will take them as a whole. Why can’t we treat knowledge as a similar resource? Sure, it’s not a resource we have direct access to, but as good designers we should be confident in our ability to communicate through design, as we have backup plans for when fallthrough is particularly bad. The other issue is that the player may come to the game with knowledge that they already have from forums or elsewhere. This is more concerning, but hopefully by building player trust in our design we can convince them to avoid spoilers for our game like they would for anything else they cared about a lot.

What I’ve done is create a tool that lets you map out the player’s progression in terms of what they will learn and what they need to know for each puzzle/secret. Let me show you a quick example. This is a sample game I made to show one type of puzzle organization you could come up with. It consists of 3 images and one text file, and is solved when you find the password hidden in one of the files. All of the files are used in the puzzle but I would suggest starting with the word search.

<img src="/assets/img/epistagraph/word_search.png" alt="drawing" width="400"/>

<img src="/assets/img/epistagraph/pic.png" alt="drawing" width="400"/>

<img src="/assets/img/epistagraph/crossword.png" alt="drawing" width="400"/>

[Clues.txt](/assets/img/epistagraph/clues.txt)

If you want to solve it do so before I spoil it ahead. Without further ado, here is the diagram I made in Epistagraph to visualize this puzzle system:

<iframe src="/assets/godot/word_search/Epistagraph.html" style="width:1080px;height:720px;border:0"></iframe>

There are two main takaways from seeing the puzzles visualized like this. The first is the structure of the puzzles and information flow. This style of puzzle is somewhat linear, but reuses most of it's elements for more than one thing, especially the word search, which was somewhat of a focal point in this puzzle system. As we will see later this can be changed to make lots of different configurations, and is often tied in heavily with the level design when placed in more traditional games. The more complex this web of connections is, the more complicated your puzzle system is likely to be, so keep that in mind and make sure to allow lots of differnt sources of the same knowlege if your game is big and it's not likely the player will see all of it in one go.

The other thing to take note of is the "knowlege required:" field, and how some of them say things like "general: ..." and have no connection attatched. These are known as entry points, and point out pieces of information your player will be expected to know from outside the game or area you are analyzing. This is important, as players will want to apply what they know in the real world to the game, but it also serves as a way of tracking difficulty in your puzzles. If your puzzles require a lot of really obscure facts, or skills the player is not likely to know they need going in, then your game might be way too hard. An example of this can be found in the early puzzle design of zork, which has a puzzle that requires knowledge of baseball, something players of a fantasy role playing game are likely to be confused by.

To show how this can be used more broadly I have included an analysis of two games that I love, The Witness and Noita. One does it’s secret discovery very well, and the other… well it has some issues. Spoilers ahead but I will constrain my scope for the sake of my time and so that I don’t take away anyone’s discovery of these games.

<iframe src="/assets/godot/witness_desert/Epistagraph.html" style="width:1080px;height:720px;border:0"></iframe>

While making this graph for the desert area I noticed that it seemed like this area was designed for a specific experience. All the nodes expanded on past ideas, not just linearly, but also using lessons from puzzles several steps behind. The most interesting thing I noticed was how many outputs led into the secrets for the area. In my experience playing the game I found that all this was not enough to show me the secret on it’s own. It was more like the experience you get in a mystery novel or movie where once you understand the truth at the end of the book, you go back and find all the clues that could have tipped you off. It can be quite satisfying if done well, and even if you give away a little too much you can often make the player feel smart anyways.

<iframe src="/assets/godot/noita_secret/Epistagraph.html" style="width:1080px;height:720px;border:0"></iframe>

For the noita secret quest line we can see that there are far more obscure and obtuse knowledge checks, some of which would probably only be solved by trail and error, which is the least interesting puzzle solving method to me. Knowledge of the anvil room is probably the biggest culprit here, though I think the biome you need to go to next would be nice if it was signposted better, even though they are in sequential order. One of the cooler ideas though was having the broken wand passively teach you about this mechanic, allowing players to apply knowledge from outside the questline. I would need to check the item descriptions, but if the broken wand told you where to find the anvil I feel like most of my problems would be resolved. That and a note telling you that the portal needed to be fired at a certain location. I feel like I would try to use my spell crafting knowledge to solve this to no avail, a knowledge base that I think is underutilized in this game’s secrets thus far.

So we’ve seen what the tool can do, but you may be asking exactly what it’s all for. Well in a nutshell it can be used to target an area of your game that is missing tutorialization or expects too much of your players. I would say that it’s more useful as a proof of concept though. It’s not too hard to keep a rough idea of what your knowledge map looks like in your head and most pain points will come up in playtesting. The hard part is targeting what to fix after seeing what the playtesters are struggling with, and I think just having an understanding of how knowledge flows in your game should be enough to work through any problems. I myself think it will be particularly useful for mapping out ARGs or secrets in games, as it’s very easy to get in a habit of making a linear sequence if you don’t plan from the start, and adding in branching paths and red herrings adds a lot of interest to a secret or ARG if done well.

There are also a number of adjacent technologies that the astute among you might be dying to tell me about, so let me address the ones I’m already aware of. First up is the idea of a concept map, which is basically a diagram that shows information dependencies. An example might be a diagram of all the knowledge needed to pass a physics course, with many of the nodes needing information from another node, creating a hierarchy of information. This is pretty close to what I’ve done, but it doesn’t take into account breakpoints where outside knowledge is used, and also doesn’t separate the knowledge itself from the thing that creates it, which in the case of a puzzle is an important distinction. Two puzzles, or even a puzzle and some other experience like an object the player notices in the world, can both contribute to the same knowledge input.

Another more game related piece of tech is the tool Skill Atoms. This is also pretty close, but instead of focusing on the meta structure of full puzzles, it goes as granular as possible. While this can result in some really cool ideas for emergent gameplay, it takes more complex puzzles that are typically seen in ARG type games off the table. Something like a code that the player uses later in the game doesn’t map well onto skill atoms, it’s still a great tool for skill based progression though.

It does open up an interesting argument about skill based progression as opposed to knowledge based progression. I think that these two are often more similar than they first appear. Skill is the process the player does to achieve an outcome in the game, whereas knowledge is a thing the player can gain by doing a sort of epistemic process. In both cases the process is what we should focus on and analyze, the main difference being that the knowledge process is much easier to “cheat” and find a solution online. For competitive games you may just need to accept that the media landscape is better equipped to communicate effectively to the playerbase, but even in those cases we can hope to learn what makes them successful and apply them to our designs.

Finally we have Machinations, a favorite of systems based designers. The problem here, and it’s probably already obvious, is that you can’t just shuffle around and trade information. It’s in the player’s head and unless we start really ramping up what DRM is allowed to do we can’t exactly take it back out. It does well with more traditional economies and system loops. Definitely a good tool when your inputs and outputs are more concrete.

As a fun aside at the end here, we might ask what this could be used for in terms of automation or procedurally generated content. Unfortunately I think the application is limited, until the inputs and outputs become more accessible, which will be impossible for some games. The best use case I can imagine would be to think of each node through the lens of information theory and assign it an uncertainty value. This value represents how many feasible solutions the player might try, but are ultimately incorrect. The higher the number the less likely the player will stumble upon an answer. Each piece of information on the input side could then correspond to the number of possibilities it crosses off the list, reducing the uncertainty, or in info theory jargon: informational entropy. Again, super impractical and definitely limits the use cases of the tool, but for games where a monte carlo simulation or other similar test is possible, it might make a good candidate for this kind of integration.

{% include open-embed.html %}
